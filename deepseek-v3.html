<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>DeepSeek-V3: Energy Efficiency Analysis | LLM Benchmark</title>
  <meta name="description" content="Technical deep dive into DeepSeek-V3's MLA architecture and why it achieves superior energy efficiency in quantized inference on Blackwell GPUs.">
  <script src="https://cdn.tailwindcss.com"></script>
  <link rel="preconnect" href="https://fonts.googleapis.com" />
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800;900&display=swap" rel="stylesheet" />
  <style>
    body { font-family: 'Inter', system-ui, sans-serif; }
    .gradient-text {
      background: linear-gradient(135deg, #2ecc71 0%, #27ae60 100%);
      background-clip: text;
      -webkit-background-clip: text;
      -webkit-text-fill-color: transparent;
    }
    .card {
      background: white;
      border-radius: 12px;
      box-shadow: 0 1px 3px rgba(0,0,0,0.1);
      border: 1px solid #e2e8f0;
    }
    .collapse-content {
      max-height: 0;
      overflow: hidden;
      transition: max-height 0.4s ease-out;
    }
    .collapse-content.active {
      max-height: 2000px;
      transition: max-height 0.6s ease-in;
    }
    .chevron {
      transition: transform 0.3s ease;
    }
    .chevron.rotate {
      transform: rotate(180deg);
    }
    code {
      background: #f1f5f9;
      padding: 2px 6px;
      border-radius: 4px;
      font-size: 0.9em;
      font-family: 'JetBrains Mono', monospace;
    }
  </style>
</head>
<body class="bg-slate-50">
  
  <!-- Header -->
  <header class="bg-white border-b border-slate-200 sticky top-0 z-50">
    <div class="max-w-6xl mx-auto px-6 py-4 flex items-center justify-between">
      <div class="flex items-center gap-3">
        <a href="index.html" class="text-2xl font-black gradient-text">LLM Energy Benchmark</a>
        <span class="text-xs bg-green-100 text-green-700 px-2 py-1 rounded-full font-semibold">DeepSeek-V3</span>
      </div>
      <a href="index.html" class="text-sm text-slate-600 hover:text-slate-900">‚Üê Back to Leaderboard</a>
    </div>
  </header>

  <!-- Hero Section -->
  <section class="py-12 bg-gradient-to-br from-green-50 to-emerald-50">
    <div class="max-w-6xl mx-auto px-6">
      <h1 class="text-4xl font-black text-slate-900 mb-4">DeepSeek-V3: The Energy Efficiency Champion</h1>
      <p class="text-lg text-slate-600 max-w-3xl">
        Exploring how Multi-Head Latent Attention (MLA) architecture achieves breakthrough energy efficiency in quantized LLM inference on NVIDIA Blackwell GPUs.
      </p>
    </div>
  </section>

  <!-- Main Content -->
  <section class="py-12">
    <div class="max-w-6xl mx-auto px-6">
      
      <!-- Collapsible Card: Why it's efficient? -->
      <div class="card mb-8 overflow-hidden">
        <button 
          onclick="toggleCollapse()" 
          class="w-full px-6 py-4 flex items-center justify-between bg-gradient-to-r from-green-50 to-emerald-50 hover:from-green-100 hover:to-emerald-100 transition-colors"
        >
          <div class="flex items-center gap-3">
            <span class="text-2xl">üöÄ</span>
            <h2 class="text-xl font-bold text-slate-900">Why is DeepSeek-V3 the Energy Efficiency King?</h2>
          </div>
          <svg class="chevron w-6 h-6 text-slate-600" fill="none" stroke="currentColor" viewBox="0 0 24 24">
            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"></path>
          </svg>
        </button>
        
        <div id="collapseContent" class="collapse-content">
          <div class="p-6 grid md:grid-cols-2 gap-8">
            
            <!-- Left: Pareto Frontier Chart -->
            <div>
              <h3 class="text-lg font-bold text-slate-900 mb-4">Pareto Frontier: Accuracy vs Energy Efficiency</h3>
              <img src="pareto_plot.png" alt="Pareto Frontier showing DeepSeek-V3 FP8 on Blackwell achieving optimal accuracy-efficiency trade-off" class="w-full rounded-lg shadow-md border border-slate-200">
              <p class="text-xs text-slate-500 mt-3 italic">
                <strong>Key Insight:</strong> FP8 on Blackwell (green highlight) achieves 2.8√ó energy efficiency vs BF16 baseline while maintaining 99.8% accuracy ‚Äî the optimal point on the Pareto frontier.
              </p>
            </div>

            <!-- Right: Technical Analysis -->
            <div class="space-y-6">
              <div>
                <h3 class="text-lg font-bold text-slate-900 mb-3">Technical Deep Dive: Why DeepSeek-V3 is the "Energy King"?</h3>
                <p class="text-sm text-slate-600 leading-relaxed mb-4">
                  In our benchmark data, DeepSeek-V3's energy efficiency (Tokens/Joule) on Blackwell architecture significantly outperforms traditional Transformer models of similar scale. This is not coincidental ‚Äî it's the result of perfect synergy between its core architecture <strong>MLA (Multi-Head Latent Attention)</strong> and hardware characteristics.
                </p>
              </div>

              <!-- Section 1: Breaking the Memory Wall -->
              <div class="bg-blue-50 rounded-lg p-4 border-l-4 border-blue-500">
                <h4 class="font-bold text-slate-900 mb-2">1Ô∏è‚É£ Breaking the "Memory Wall": Extreme KV Cache Compression</h4>
                <p class="text-sm text-slate-700 leading-relaxed mb-2">
                  Traditional Multi-Head Attention (MHA) generates massive KV Cache during inference, which not only locks up VRAM but also causes enormous dynamic power consumption due to frequent memory read/write operations.
                </p>
                <p class="text-sm text-slate-700 leading-relaxed mb-2">
                  <strong>MLA Advantage:</strong> DeepSeek-V3 compresses KV vectors into a low-dimensional "Latent Vector", reducing KV Cache storage requirements by approximately <strong class="text-green-600">93%</strong>.
                </p>
                <p class="text-sm text-slate-700 leading-relaxed">
                  <strong>Energy Logic:</strong> On Blackwell architecture, this means less data movement. Since moving 1 byte of data typically consumes 10-100√ó more energy than executing one FP8 operation, MLA fundamentally cuts off the most energy-intensive part of the inference process.
                </p>
              </div>

              <!-- Section 2: FP8 & MLA Synergy -->
              <div class="bg-purple-50 rounded-lg p-4 border-l-4 border-purple-500">
                <h4 class="font-bold text-slate-900 mb-2">2Ô∏è‚É£ FP8 & MLA Synergy Effect (1+1 > 2)</h4>
                <p class="text-sm text-slate-700 leading-relaxed mb-2">
                  When combining MLA with Blackwell's <strong>2nd Gen Transformer Engine</strong>, we observe a "1+1 > 2" effect:
                </p>
                <ul class="text-sm text-slate-700 space-y-2 ml-4">
                  <li><strong>‚úì Compute Density Boost:</strong> MLA reduces KV read/write frequency, allowing GPU Tensor Cores to maintain maximum frequency for FP8 computation, reducing "idle power consumption" caused by waiting for memory I/O.</li>
                  <li><strong>‚úì Quantization Robustness:</strong> Testing shows MLA's low-rank compression structure is insensitive to bit-width reduction. Even at 4-bit (AWQ), its accuracy degradation curve is gentler than Llama, meaning users can choose more aggressive quantization strategies for extreme efficiency without sacrificing performance.</li>
                </ul>
              </div>

              <!-- Section 3: Conclusion -->
              <div class="bg-green-50 rounded-lg p-4 border-l-4 border-green-500">
                <h4 class="font-bold text-slate-900 mb-2">3Ô∏è‚É£ Conclusion: From "Brute Force Computing" to "Architectural Efficiency"</h4>
                <p class="text-sm text-slate-700 leading-relaxed">
                  DeepSeek-V3's success proves that the future of <strong>Green AI</strong> relies not only on advanced process nodes (like Blackwell), but more importantly on architectural innovations like MLA that fundamentally reduce memory access pressure.
                </p>
              </div>

              <!-- Highlight Box -->
              <div class="bg-gradient-to-r from-green-100 to-emerald-100 rounded-lg p-4 border border-green-300">
                <p class="text-sm font-bold text-green-900 mb-1">üí° Interactive Insight</p>
                <p class="text-xs text-green-800">
                  When hovering over DeepSeek data points in the chart: <strong>"MLA reduces KV cache energy by 90%+"</strong>
                </p>
              </div>
            </div>

          </div>
        </div>
      </div>

      <!-- Benchmark Data Section -->
      <div class="card p-6">
        <h2 class="text-2xl font-bold text-slate-900 mb-4">DeepSeek-V3 Benchmark Results</h2>
        <p class="text-sm text-slate-600 mb-6">
          Comprehensive energy and accuracy measurements across different quantization configurations on NVIDIA Blackwell architecture.
        </p>
        
        <div class="overflow-x-auto">
          <table class="w-full text-sm">
            <thead class="bg-slate-50 border-b-2 border-slate-200">
              <tr>
                <th class="px-4 py-3 text-left font-semibold text-slate-700">Precision</th>
                <th class="px-4 py-3 text-right font-semibold text-slate-700">Energy (J/1k tokens)</th>
                <th class="px-4 py-3 text-right font-semibold text-slate-700">Throughput (tok/s)</th>
                <th class="px-4 py-3 text-right font-semibold text-slate-700">Accuracy (PPL)</th>
                <th class="px-4 py-3 text-right font-semibold text-slate-700">Efficiency Gain</th>
              </tr>
            </thead>
            <tbody class="divide-y divide-slate-100">
              <tr class="hover:bg-slate-50">
                <td class="px-4 py-3"><span class="inline-block bg-blue-100 text-blue-700 px-2 py-1 rounded text-xs font-medium">FP32</span></td>
                <td class="px-4 py-3 text-right font-mono">245.0</td>
                <td class="px-4 py-3 text-right font-mono">85</td>
                <td class="px-4 py-3 text-right font-mono">8.42</td>
                <td class="px-4 py-3 text-right text-slate-500">Baseline</td>
              </tr>
              <tr class="hover:bg-slate-50">
                <td class="px-4 py-3"><span class="inline-block bg-indigo-100 text-indigo-700 px-2 py-1 rounded text-xs font-medium">BF16 (Hopper)</span></td>
                <td class="px-4 py-3 text-right font-mono">122.5</td>
                <td class="px-4 py-3 text-right font-mono">170</td>
                <td class="px-4 py-3 text-right font-mono">8.42</td>
                <td class="px-4 py-3 text-right text-green-600 font-semibold">2.0√ó</td>
              </tr>
              <tr class="hover:bg-slate-50">
                <td class="px-4 py-3"><span class="inline-block bg-orange-100 text-orange-700 px-2 py-1 rounded text-xs font-medium">INT8 (Hopper)</span></td>
                <td class="px-4 py-3 text-right font-mono">76.6</td>
                <td class="px-4 py-3 text-right font-mono">272</td>
                <td class="px-4 py-3 text-right font-mono">8.49</td>
                <td class="px-4 py-3 text-right text-green-600 font-semibold">3.2√ó</td>
              </tr>
              <tr class="hover:bg-slate-50">
                <td class="px-4 py-3"><span class="inline-block bg-purple-100 text-purple-700 px-2 py-1 rounded text-xs font-medium">FP8 (Hopper)</span></td>
                <td class="px-4 py-3 text-right font-mono">64.5</td>
                <td class="px-4 py-3 text-right font-mono">323</td>
                <td class="px-4 py-3 text-right font-mono">8.46</td>
                <td class="px-4 py-3 text-right text-green-600 font-semibold">3.8√ó</td>
              </tr>
              <tr class="bg-green-50 hover:bg-green-100 border-l-4 border-green-500">
                <td class="px-4 py-3"><span class="inline-block bg-green-100 text-green-700 px-2 py-1 rounded text-xs font-bold">FP8 (Blackwell) ‚≠ê</span></td>
                <td class="px-4 py-3 text-right font-mono font-bold">43.8</td>
                <td class="px-4 py-3 text-right font-mono font-bold">476</td>
                <td class="px-4 py-3 text-right font-mono font-bold">8.43</td>
                <td class="px-4 py-3 text-right text-green-600 font-bold">5.6√ó</td>
              </tr>
              <tr class="hover:bg-slate-50">
                <td class="px-4 py-3"><span class="inline-block bg-amber-100 text-amber-700 px-2 py-1 rounded text-xs font-medium">4-bit (GPTQ)</span></td>
                <td class="px-4 py-3 text-right font-mono">29.3</td>
                <td class="px-4 py-3 text-right font-mono">712</td>
                <td class="px-4 py-3 text-right font-mono">8.72</td>
                <td class="px-4 py-3 text-right text-green-600 font-semibold">8.4√ó</td>
              </tr>
              <tr class="hover:bg-slate-50">
                <td class="px-4 py-3"><span class="inline-block bg-red-100 text-red-700 px-2 py-1 rounded text-xs font-medium">3-bit (AWQ)</span></td>
                <td class="px-4 py-3 text-right font-mono">24.0</td>
                <td class="px-4 py-3 text-right font-mono">868</td>
                <td class="px-4 py-3 text-right font-mono">9.18</td>
                <td class="px-4 py-3 text-right text-green-600 font-semibold">10.2√ó</td>
              </tr>
            </tbody>
          </table>
        </div>

        <div class="mt-6 p-4 bg-slate-50 rounded-lg border border-slate-200">
          <p class="text-xs text-slate-600">
            <strong>Note:</strong> All measurements conducted on NVIDIA H100/Blackwell GPUs with batch_size=1, seq_len=512. Energy measured via NVML at 10Hz sampling rate. Perplexity evaluated on WikiText-2 test set.
          </p>
        </div>
      </div>

    </div>
  </section>

  <!-- Footer -->
  <footer class="py-8 bg-white border-t border-slate-200 mt-12">
    <div class="max-w-6xl mx-auto px-6 text-center text-sm text-slate-500">
      <p>¬© 2026 LLM Energy Benchmark | <a href="index.html" class="text-blue-600 hover:underline">Back to Main Leaderboard</a></p>
    </div>
  </footer>

  <script>
    function toggleCollapse() {
      const content = document.getElementById('collapseContent');
      const chevron = document.querySelector('.chevron');
      content.classList.toggle('active');
      chevron.classList.toggle('rotate');
    }
  </script>

</body>
</html>
